{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "str expected, not bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8a389431c0c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'KMP_DUPLICATE_LIB_OK'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    681\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodekey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/os.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"str expected, not %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogateescape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: str expected, not bool"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Masking\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as k\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Discrete log-likelihood for Weibull hazard function on censored survival data\n",
    "    y_true is a (samples, 2) tensor containing time-to-event (y), and an event indicator (u)\n",
    "    ab_pred is a (samples, 2) tensor containing predicted Weibull alpha (a) and beta (b) parameters\n",
    "    For math, see https://ragulpr.github.io/assets/draft_master_thesis_martinsson_egil_wtte_rnn_2016.pdf (Page 35)\n",
    "\"\"\"\n",
    "def weibull_loglik_discrete(y_true, ab_pred, name=None):\n",
    "    y_ = y_true[:, 0]\n",
    "    u_ = y_true[:, 1]\n",
    "    a_ = ab_pred[:, 0]\n",
    "    b_ = ab_pred[:, 1]\n",
    "\n",
    "    hazard0 = k.pow((y_ + 1e-35) / a_, b_)\n",
    "    hazard1 = k.pow((y_ + 1) / a_, b_)\n",
    "\n",
    "    return -1 * k.mean(u_ * k.log(k.exp(hazard1 - hazard0) - 1.0) - hazard1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Not used for this model, but included in case somebody needs it\n",
    "    For math, see https://ragulpr.github.io/assets/draft_master_thesis_martinsson_egil_wtte_rnn_2016.pdf (Page 35)\n",
    "\"\"\"\n",
    "def weibull_loglik_continuous(y_true, ab_pred, name=None):\n",
    "    y_ = y_true[:, 0]\n",
    "    u_ = y_true[:, 1]\n",
    "    a_ = ab_pred[:, 0]\n",
    "    b_ = ab_pred[:, 1]\n",
    "\n",
    "    ya = (y_ + 1e-35) / a_\n",
    "    return -1 * k.mean(u_ * (k.log(b_) + b_ * k.log(ya)) - k.pow(ya, b_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Custom Keras activation function, outputs alpha neuron using exponentiation and beta using softplus\n",
    "\"\"\"\n",
    "def activate(ab):\n",
    "    a = k.exp(ab[:, 0])\n",
    "    b = k.softplus(ab[:, 1])\n",
    "\n",
    "    a = k.reshape(a, (k.shape(a)[0], 1))\n",
    "    b = k.reshape(b, (k.shape(b)[0], 1))\n",
    "\n",
    "    return k.concatenate((a, b), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Load and parse engine data files into:\n",
    "       - an (engine/day, observed history, sensor readings) x tensor, where observed history is 100 days, zero-padded\n",
    "         for days that don't have a full 100 days of observed history (e.g., first observed day for an engine)\n",
    "       - an (engine/day, 2) tensor containing time-to-event and 1 (since all engines failed)\n",
    "\n",
    "    There are probably MUCH better ways of doing this, but I don't use Numpy that much, and the data parsing isn't the\n",
    "    point of this demo anyway.\n",
    "\"\"\"\n",
    "def load_file(name):\n",
    "    with open(name, 'r') as file:\n",
    "        return np.loadtxt(file, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, threshold=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_file('train.csv')\n",
    "test_x = load_file('test_x.csv')\n",
    "test_y = load_file('test_y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the X values to normalize them, then split them back out\n",
    "all_x = np.concatenate((train[:, 2:26], test_x[:, 2:26]))\n",
    "all_x = normalize(all_x, axis=0)\n",
    "\n",
    "train[:, 2:26] = all_x[0:train.shape[0], :]\n",
    "test_x[:, 2:26] = all_x[train.shape[0]:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make engine numbers and days zero-indexed, for everybody's sanity\n",
    "train[:, 0:2] -= 1\n",
    "test_x[:, 0:2] -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurable observation look-back period for each engine/day\n",
    "max_time = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(engine, time, x, max_time, is_test):\n",
    "    # y[0] will be days remaining, y[1] will be event indicator, always 1 for this data\n",
    "    out_y = np.empty((0, 2), dtype=np.float32)\n",
    "\n",
    "    # A full history of sensor readings to date for each x\n",
    "    out_x = np.empty((0, max_time, 24), dtype=np.float32)\n",
    "\n",
    "    for i in range(100):\n",
    "        print(\"Engine: \" + str(i))\n",
    "        # When did the engine fail? (Last day + 1 for train data, irrelevant for test.)\n",
    "        max_engine_time = int(np.max(time[engine == i])) + 1\n",
    "\n",
    "        if is_test:\n",
    "            start = max_engine_time - 1\n",
    "        else:\n",
    "            start = 0\n",
    "\n",
    "        this_x = np.empty((0, max_time, 24), dtype=np.float32)\n",
    "\n",
    "        for j in range(start, max_engine_time):\n",
    "            engine_x = x[engine == i]\n",
    "\n",
    "            out_y = np.append(out_y, np.array((max_engine_time - j, 1), ndmin=2), axis=0)\n",
    "\n",
    "            xtemp = np.zeros((1, max_time, 24))\n",
    "            xtemp[:, max_time-min(j, 99)-1:max_time, :] = engine_x[max(0, j-max_time+1):j+1, :]\n",
    "            this_x = np.concatenate((this_x, xtemp))\n",
    "\n",
    "        out_x = np.concatenate((out_x, this_x))\n",
    "\n",
    "    return out_x, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine: 0\n",
      "Engine: 1\n",
      "Engine: 2\n",
      "Engine: 3\n",
      "Engine: 4\n",
      "Engine: 5\n",
      "Engine: 6\n",
      "Engine: 7\n",
      "Engine: 8\n",
      "Engine: 9\n",
      "Engine: 10\n",
      "Engine: 11\n",
      "Engine: 12\n",
      "Engine: 13\n",
      "Engine: 14\n",
      "Engine: 15\n",
      "Engine: 16\n",
      "Engine: 17\n",
      "Engine: 18\n",
      "Engine: 19\n",
      "Engine: 20\n",
      "Engine: 21\n",
      "Engine: 22\n",
      "Engine: 23\n",
      "Engine: 24\n",
      "Engine: 25\n",
      "Engine: 26\n",
      "Engine: 27\n",
      "Engine: 28\n",
      "Engine: 29\n",
      "Engine: 30\n",
      "Engine: 31\n",
      "Engine: 32\n",
      "Engine: 33\n",
      "Engine: 34\n",
      "Engine: 35\n",
      "Engine: 36\n",
      "Engine: 37\n",
      "Engine: 38\n",
      "Engine: 39\n",
      "Engine: 40\n",
      "Engine: 41\n",
      "Engine: 42\n",
      "Engine: 43\n",
      "Engine: 44\n",
      "Engine: 45\n",
      "Engine: 46\n",
      "Engine: 47\n",
      "Engine: 48\n",
      "Engine: 49\n",
      "Engine: 50\n",
      "Engine: 51\n",
      "Engine: 52\n",
      "Engine: 53\n",
      "Engine: 54\n",
      "Engine: 55\n",
      "Engine: 56\n",
      "Engine: 57\n",
      "Engine: 58\n",
      "Engine: 59\n",
      "Engine: 60\n",
      "Engine: 61\n",
      "Engine: 62\n",
      "Engine: 63\n",
      "Engine: 64\n",
      "Engine: 65\n",
      "Engine: 66\n",
      "Engine: 67\n",
      "Engine: 68\n",
      "Engine: 69\n",
      "Engine: 70\n",
      "Engine: 71\n",
      "Engine: 72\n",
      "Engine: 73\n",
      "Engine: 74\n",
      "Engine: 75\n",
      "Engine: 76\n",
      "Engine: 77\n",
      "Engine: 78\n",
      "Engine: 79\n",
      "Engine: 80\n",
      "Engine: 81\n",
      "Engine: 82\n",
      "Engine: 83\n",
      "Engine: 84\n",
      "Engine: 85\n",
      "Engine: 86\n",
      "Engine: 87\n",
      "Engine: 88\n",
      "Engine: 89\n",
      "Engine: 90\n",
      "Engine: 91\n",
      "Engine: 92\n",
      "Engine: 93\n",
      "Engine: 94\n",
      "Engine: 95\n",
      "Engine: 96\n",
      "Engine: 97\n",
      "Engine: 98\n",
      "Engine: 99\n",
      "Engine: 0\n",
      "Engine: 1\n",
      "Engine: 2\n",
      "Engine: 3\n",
      "Engine: 4\n",
      "Engine: 5\n",
      "Engine: 6\n",
      "Engine: 7\n",
      "Engine: 8\n",
      "Engine: 9\n",
      "Engine: 10\n",
      "Engine: 11\n",
      "Engine: 12\n",
      "Engine: 13\n",
      "Engine: 14\n",
      "Engine: 15\n",
      "Engine: 16\n",
      "Engine: 17\n",
      "Engine: 18\n",
      "Engine: 19\n",
      "Engine: 20\n",
      "Engine: 21\n",
      "Engine: 22\n",
      "Engine: 23\n",
      "Engine: 24\n",
      "Engine: 25\n",
      "Engine: 26\n",
      "Engine: 27\n",
      "Engine: 28\n",
      "Engine: 29\n",
      "Engine: 30\n",
      "Engine: 31\n",
      "Engine: 32\n",
      "Engine: 33\n",
      "Engine: 34\n",
      "Engine: 35\n",
      "Engine: 36\n",
      "Engine: 37\n",
      "Engine: 38\n",
      "Engine: 39\n",
      "Engine: 40\n",
      "Engine: 41\n",
      "Engine: 42\n",
      "Engine: 43\n",
      "Engine: 44\n",
      "Engine: 45\n",
      "Engine: 46\n",
      "Engine: 47\n",
      "Engine: 48\n",
      "Engine: 49\n",
      "Engine: 50\n",
      "Engine: 51\n",
      "Engine: 52\n",
      "Engine: 53\n",
      "Engine: 54\n",
      "Engine: 55\n",
      "Engine: 56\n",
      "Engine: 57\n",
      "Engine: 58\n",
      "Engine: 59\n",
      "Engine: 60\n",
      "Engine: 61\n",
      "Engine: 62\n",
      "Engine: 63\n",
      "Engine: 64\n",
      "Engine: 65\n",
      "Engine: 66\n",
      "Engine: 67\n",
      "Engine: 68\n",
      "Engine: 69\n",
      "Engine: 70\n",
      "Engine: 71\n",
      "Engine: 72\n",
      "Engine: 73\n",
      "Engine: 74\n",
      "Engine: 75\n",
      "Engine: 76\n",
      "Engine: 77\n",
      "Engine: 78\n",
      "Engine: 79\n",
      "Engine: 80\n",
      "Engine: 81\n",
      "Engine: 82\n",
      "Engine: 83\n",
      "Engine: 84\n",
      "Engine: 85\n",
      "Engine: 86\n",
      "Engine: 87\n",
      "Engine: 88\n",
      "Engine: 89\n",
      "Engine: 90\n",
      "Engine: 91\n",
      "Engine: 92\n",
      "Engine: 93\n",
      "Engine: 94\n",
      "Engine: 95\n",
      "Engine: 96\n",
      "Engine: 97\n",
      "Engine: 98\n",
      "Engine: 99\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = build_data(train[:, 0], train[:, 1], train[:, 2:26], max_time, False)\n",
    "test_x = build_data(test_x[:, 0], test_x[:, 1], test_x[:, 2:26], max_time, True)[0]\n",
    "\n",
    "train_u = np.zeros((100, 1), dtype=np.float32)\n",
    "train_u += 1\n",
    "test_y = np.append(np.reshape(test_y, (100, 1)), train_u, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/simon/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  del sys.path[0]\n",
      "/Users/simon/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(20, input_shape=(None, 24))`\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Here's the rest of the meat of the demo... actually fitting and training the model.\n",
    "    We'll also make some test predictions so we can evaluate model performance.\n",
    "\"\"\"\n",
    "\n",
    "# Start building our model\n",
    "model = Sequential()\n",
    "\n",
    "# Mask parts of the lookback period that are all zeros (i.e., unobserved) so they don't skew the model\n",
    "model.add(Masking(mask_value=0., input_shape=(max_time, 24)))\n",
    "\n",
    "# LSTM is just a common type of RNN. You could also try anything else (e.g., GRU).\n",
    "model.add(LSTM(20, input_dim=24))\n",
    "\n",
    "# We need 2 neurons to output Alpha and Beta parameters for our Weibull distribution\n",
    "model.add(Dense(2))\n",
    "\n",
    "# Apply the custom activation function mentioned above\n",
    "model.add(Activation(activate))\n",
    "\n",
    "# Use the discrete log-likelihood for Weibull survival data as our loss function\n",
    "model.compile(loss=weibull_loglik_discrete, optimizer=RMSprop(lr=.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/simon/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20631 samples, validate on 100 samples\n",
      "Epoch 1/250\n"
     ]
    }
   ],
   "source": [
    "# Fit!\n",
    "model.fit(train_x, train_y, nb_epoch=250, batch_size=2000, verbose=1, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions and put them alongside the real TTE and event indicator values\n",
    "test_predict = model.predict(test_x)\n",
    "test_predict = np.resize(test_predict, (100, 2))\n",
    "test_result = np.concatenate((test_y, test_predict), axis=1)\n",
    "\n",
    "# TTE, Event Indicator, Alpha, Beta\n",
    "print(test_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
